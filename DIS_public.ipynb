{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "1pkIbufi2PgdM-he4u9O8FNdWy9YFes4I",
      "authorship_tag": "ABX9TyOOnUB7MttdYmLDLMUyq7O5",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/olaviinha/NeuralBackgroundRemoval/blob/main/DIS_public.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#<font face=\"Trebuchet MS\" size=\"6\">DIS IS-Net<font color=\"#999\" size=\"4\">&nbsp;&nbsp;&nbsp;|&nbsp;&nbsp;&nbsp;</font><font color=\"#999\" size=\"4\">Background removal</font><font color=\"#999\" size=\"4\">&nbsp;&nbsp;&nbsp;|&nbsp;&nbsp;&nbsp;</font><a href=\"https://github.com/olaviinha/NeuralBackgroundRemoval\" target=\"_blank\"><font color=\"#999\" size=\"4\">Github</font></a>\n",
        "\n",
        "Colab for [Highly Accurate Dichotomous Image Segmentation](https://arxiv.org/pdf/2203.03041.pdf) by Xuebin Qin et al.\n",
        "\n",
        "<font color=\"salmon\">Note!</font> In light of Google Colab's recent price hike circus, please note that running this notebook is probably entirely tolerable on CPU only runtime (without GPU). Images are processed within seconds on CPU.\n",
        "\n",
        "### Tips\n",
        "\n",
        "- All directory and file paths should be relative to your Google Drive root: e.g. if you have a directory called _images_ in your Drive, containing a subdirectory called _churchboats_, then the field value in this notebook should be `images/churchboats`.\n",
        "\n",
        "- `input` may be a path to an image file or a directory containing image files. All images found from the directory will be individually processed (images in subdirs not included).\n",
        "\n",
        "- If you provide a `local_models_dir` path, all models will be fetched from there instead of being downloaded. If models are not found from the given path, they will be downloaded there first. Using this may be useful in the future if models are no longer available in their current locations.\n",
        "\n",
        "- `end_session_when_done` disconnects and deletes runtime upon cell completion. Mostly useful if you are processing a large number of images on a GPU runtime."
      ],
      "metadata": {
        "id": "JtBhIo2BDlG2"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "8OlG5xyqx6ZF"
      },
      "outputs": [],
      "source": [
        "#@title #Setup\n",
        "#@markdown This cell needs to be run only once. It will mount your Google Drive and setup prerequisites.<br>\n",
        "#@markdown <small>Mounting Drive will enable this notebook to save outputs directly to your Drive. Otherwise you will need to copy/download them manually from this notebook.</small>\n",
        "\n",
        "force_setup = False\n",
        "repositories = [\n",
        "  # 'https://github.com/xuebinqin/U-2-Net',\n",
        "  'https://github.com/xuebinqin/DIS'\n",
        "  # 'https://github.com/xuebinqin/DIS'\n",
        "]\n",
        "pip_packages = ''\n",
        "apt_packages = ''\n",
        "mount_drive = True #@param {type:\"boolean\"}\n",
        "local_models_dir = \"\" #@param {type:\"string\"}\n",
        "skip_setup = False #@ param {type:\"boolean\"}\n",
        "\n",
        "# Download the repo from Github\n",
        "import os\n",
        "from google.colab import output\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "%cd /content/\n",
        "\n",
        "# inhagcutils\n",
        "if not os.path.isfile('/content/inhagcutils.ipynb') and force_setup == False:\n",
        "  !pip -q install import-ipynb {pip_packages}\n",
        "  if apt_packages != '':\n",
        "    !apt-get update && apt-get install {apt_packages}\n",
        "  !curl -s -O https://raw.githubusercontent.com/olaviinha/inhagcutils/master/inhagcutils.ipynb\n",
        "import import_ipynb\n",
        "from inhagcutils import *\n",
        "\n",
        "# Mount Drive\n",
        "if mount_drive is True:\n",
        "  if not os.path.isdir('/content/drive'):\n",
        "    from google.colab import drive\n",
        "    drive.mount('/content/drive')\n",
        "    drive_root = '/content/drive/My Drive'\n",
        "  if not os.path.isdir('/content/mydrive'):\n",
        "    os.symlink('/content/drive/My Drive', '/content/mydrive')\n",
        "    drive_root = '/content/mydrive/'\n",
        "  drive_root_set = True\n",
        "else:\n",
        "  create_dirs(['/content/faux_drive'])\n",
        "  drive_root = '/content/faux_drive/'\n",
        "\n",
        "if len(repositories) > 0:\n",
        "  if skip_setup == False:\n",
        "    for repo in repositories:\n",
        "      %cd /content/\n",
        "      install_dir = fix_path('/content/'+path_leaf(repo).replace('.git', ''))\n",
        "      repo_name = basename(install_dir)\n",
        "      repo = repo if '.git' in repo else repo+'.git'\n",
        "      !git clone {repo}\n",
        "      if os.path.isfile(install_dir+'setup.py') or os.path.isfile(install_dir+'setup.cfg'):\n",
        "        !pip install -e ./{install_dir}\n",
        "      if os.path.isfile(install_dir+'requirements.txt'):\n",
        "        !pip install -r {install_dir}/requirements.txt\n",
        "  else:\n",
        "    install_dir = fix_path('/content/'+path_leaf(repositories[0]).replace('.git', ''))\n",
        "    repo_name = path_leaf(install_dir)\n",
        "\n",
        "dir_tmp = '/content/tmp/'\n",
        "create_dirs([dir_tmp])\n",
        "\n",
        "if len(repositories) == 1:\n",
        "  %cd {install_dir}\n",
        "\n",
        "import time, sys\n",
        "from datetime import timedelta\n",
        "\n",
        "# # DO stuff\n",
        "# if repo_name == 'DIS':\n",
        "#   !gdown 1jOC2zK0GowBvEt03B7dGugCRDVAoeIqq\n",
        "\n",
        "def prep_model(model, gid):\n",
        "  global install_dir, models_dir\n",
        "  filename = model+'.pth'\n",
        "  if not os.path.isfile(models_dir+filename):\n",
        "    !gdown {gid}\n",
        "  if os.path.isfile(models_dir+filename):\n",
        "    mdir = install_dir+'saved_models/'\n",
        "    if not os.path.isdir(mdir): os.mkdir(mdir)\n",
        "    print( 'From', models_dir+filename ) \n",
        "    print(' To', mdir+filename )\n",
        "    shutil.copy(models_dir+filename, mdir+filename)\n",
        "  else:\n",
        "    op(c.fail, 'Failed', filename)\n",
        "\n",
        "if not os.path.isdir(install_dir+'saved_models/IS-Net'):\n",
        "  os.mkdir(install_dir+'saved_models/IS-Net')\n",
        "\n",
        "if local_models_dir != '':\n",
        "  models_dir = drive_root+fix_path(local_models_dir)\n",
        "  if not os.path.isdir(models_dir): os.mkdir(models_dir)\n",
        "  %cd {models_dir}\n",
        "  prep_model('isnet', '1KyMpRjewZdyYfxHPYcd-ZbanIXtin0Sn')\n",
        "  prep_model('isnet-general-use', '1nV57qKuy--d5u1yvkng9aXW1KS4sOpOi')\n",
        "\n",
        "  %cd {install_dir}\n",
        "else:\n",
        "  d = install_dir+'saved_models/IS-Net'\n",
        "  os.mkdir(d)\n",
        "  %cd {d}\n",
        "  # isnet.pth\n",
        "  !gdown 1KyMpRjewZdyYfxHPYcd-ZbanIXtin0Sn\n",
        "  # isnet-general-use.pth\n",
        "  !gdown 1nV57qKuy--d5u1yvkng9aXW1KS4sOpOi\n",
        "  \n",
        "\n",
        "%cd {install_dir}/IS-Net\n",
        "\n",
        "\n",
        "import numpy as np\n",
        "from PIL import Image, ImageEnhance\n",
        "import torch\n",
        "from torch.autograd import Variable\n",
        "from torchvision import transforms\n",
        "import torch.nn.functional as F\n",
        "import gdown\n",
        "import os\n",
        "\n",
        "import requests\n",
        "import matplotlib.pyplot as plt\n",
        "from io import BytesIO\n",
        "\n",
        "# project imports\n",
        "from data_loader_cache import normalize, im_reader, im_preprocess \n",
        "from models import *\n",
        "\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "\n",
        "%cd {install_dir}\n",
        "\n",
        "\n",
        "class GOSNormalize(object):\n",
        "    '''\n",
        "    Normalize the Image using torch.transforms\n",
        "    '''\n",
        "    def __init__(self, mean=[0.485,0.456,0.406], std=[0.229,0.224,0.225]):\n",
        "        self.mean = mean\n",
        "        self.std = std\n",
        "\n",
        "    def __call__(self,image):\n",
        "        image = normalize(image,self.mean,self.std)\n",
        "        return image\n",
        "\n",
        "\n",
        "transform =  transforms.Compose([GOSNormalize([0.5,0.5,0.5],[1.0,1.0,1.0])])\n",
        "\n",
        "def load_image(im_path, hypar):\n",
        "    if im_path.startswith(\"http\"):\n",
        "        im_path = BytesIO(requests.get(im_path).content)\n",
        "\n",
        "    im = im_reader(im_path)\n",
        "    im, im_shp = im_preprocess(im, hypar[\"cache_size\"])\n",
        "    im = torch.divide(im,255.0)\n",
        "    shape = torch.from_numpy(np.array(im_shp))\n",
        "    return transform(im).unsqueeze(0), shape.unsqueeze(0) # make a batch of image, shape\n",
        "\n",
        "\n",
        "def build_model(hypar,device):\n",
        "    net = hypar[\"model\"]#GOSNETINC(3,1)\n",
        "\n",
        "    # convert to half precision\n",
        "    if(hypar[\"model_digit\"]==\"half\"):\n",
        "        net.half()\n",
        "        for layer in net.modules():\n",
        "            if isinstance(layer, nn.BatchNorm2d):\n",
        "                layer.float()\n",
        "\n",
        "    net.to(device)\n",
        "\n",
        "    if(hypar[\"restore_model\"]!=\"\"):\n",
        "        net.load_state_dict(torch.load(hypar[\"model_path\"]+\"/\"+hypar[\"restore_model\"],map_location=device))\n",
        "        net.to(device)\n",
        "    net.eval()  \n",
        "    return net\n",
        "\n",
        "    \n",
        "def predict(net,  inputs_val, shapes_val, hypar, device):\n",
        "    '''\n",
        "    Given an Image, predict the mask\n",
        "    '''\n",
        "    net.eval()\n",
        "\n",
        "    if(hypar[\"model_digit\"]==\"full\"):\n",
        "        inputs_val = inputs_val.type(torch.FloatTensor)\n",
        "    else:\n",
        "        inputs_val = inputs_val.type(torch.HalfTensor)\n",
        "\n",
        "  \n",
        "    inputs_val_v = Variable(inputs_val, requires_grad=False).to(device) # wrap inputs in Variable\n",
        "   \n",
        "    ds_val = net(inputs_val_v)[0] # list of 6 results\n",
        "\n",
        "    pred_val = ds_val[0][0,:,:,:] # B x 1 x H x W    # we want the first one which is the most accurate prediction\n",
        "\n",
        "    ## recover the prediction spatial size to the orignal image size\n",
        "    pred_val = torch.squeeze(F.upsample(torch.unsqueeze(pred_val,0),(shapes_val[0][0],shapes_val[0][1]),mode='bilinear'))\n",
        "\n",
        "    ma = torch.max(pred_val)\n",
        "    mi = torch.min(pred_val)\n",
        "    pred_val = (pred_val-mi)/(ma-mi) # max = 1\n",
        "\n",
        "    if device == 'cuda': torch.cuda.empty_cache()\n",
        "    return (pred_val.detach().cpu().numpy()*255).astype(np.uint8) # it is the mask we need\n",
        "\n",
        "\n",
        "hypar = {} # paramters for inferencing\n",
        "\n",
        "hypar[\"model_path\"] =\"./saved_models\" ## load trained weights from this path\n",
        "hypar[\"restore_model\"] = \"isnet.pth\" ## name of the to-be-loaded weights\n",
        "hypar[\"interm_sup\"] = False ## indicate if activate intermediate feature supervision\n",
        "\n",
        "##  choose floating point accuracy --\n",
        "hypar[\"model_digit\"] = \"full\" ## indicates \"half\" or \"full\" accuracy of float number\n",
        "hypar[\"seed\"] = 0\n",
        "\n",
        "hypar[\"cache_size\"] = [1024, 1024] ## cached input spatial resolution, can be configured into different size\n",
        "\n",
        "## data augmentation parameters ---\n",
        "hypar[\"input_size\"] = [1024, 1024] ## mdoel input spatial size, usually use the same value hypar[\"cache_size\"], which means we don't further resize the images\n",
        "hypar[\"crop_size\"] = [1024, 1024] ## random crop size from the input, it is usually set as smaller than hypar[\"cache_size\"], e.g., [920,920] for data augmentation\n",
        "\n",
        "hypar[\"model\"] = ISNetDIS()\n",
        "\n",
        "\n",
        "\n",
        "net = build_model(hypar, device)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def save_output(og_img, pred, output_path, contrast=1, save_mask=False):\n",
        "  im = Image.fromarray(pred).convert('L')\n",
        "  og_image = Image.open(og_img)\n",
        "  mask = im.resize(og_image.size, resample=Image.BILINEAR)\n",
        "  if contrast != 1:\n",
        "    enhancer = ImageEnhance.Contrast(mask)\n",
        "    mask = enhancer.enhance(contrast)\n",
        "  if save_mask is True:\n",
        "    mask.save(output_path.replace('.png', '_mask.png'), 'PNG')\n",
        "  im2 = Image.open(og_img)\n",
        "  im2.putalpha(mask)\n",
        "  im2.save(output_path, 'PNG')\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# output.clear()\n",
        "op(c.ok, 'Setup finished.')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title # Run\n",
        "include_subdirs = False #@ param {type: \"boolean\"}\n",
        "input = \"\" #@param {type:\"string\"}\n",
        "output_dir = \"\" #@param {type:\"string\"}\n",
        "filename_detail = \"\" #@ param {type:\"string\"}\n",
        "# scaler = 0.5 #@param {type:\"slider\", min:0.25, max:4, step:0.25}\n",
        "# scalers = \"1\" #@param {type:\"string\"}\n",
        "model = \"isnet-general-use\" #@param [\"isnet\", \"isnet-general-use\"]\n",
        "disconnect_runtime_when_done = False #@param {type: \"boolean\"}\n",
        "\n",
        "contrast = 1\n",
        "save_mask = False\n",
        "\n",
        "model_path = install_dir+'saved_models/IS-Net/'+model+'.pth'\n",
        "model_name = basename(model_path)\n",
        "uniq_id = gen_id()\n",
        "trunc = 40\n",
        "est_per_img = 8\n",
        "\n",
        "copy_files = False\n",
        "exclude_images_containing = ['isnet', 'u2net'] # ignore images that contain these strings\n",
        "\n",
        "if os.path.isfile(drive_root+input):\n",
        "  inputs = [drive_root+input]\n",
        "  dir_in = path_dir(drive_root+input)\n",
        "  copy_files = True\n",
        "elif input != '' and os.path.isdir(drive_root+input):\n",
        "  dir_in = drive_root+fix_path(input)\n",
        "  inputs = list_images(dir_in, exclude_pattern=exclude_images_containing)\n",
        "  if include_subdirs is True:\n",
        "    dirlist = glob(dir_in+'/*')\n",
        "    for item in dirlist:\n",
        "      if os.path.isdir(item):\n",
        "        inputs.extend(list_images(item, exclude=exclude_images_containing))\n",
        "    # inputs = list(set(inputs))\n",
        "elif os.path.isdir(drive_root+input) and '*' in input:\n",
        "  dir_in = path_dir(drive_root+input)\n",
        "  inputs = glob(drive_root+input)\n",
        "  copy_files = True\n",
        "else:\n",
        "  op(c.fail, 'FAIL!', 'Input should be a path to a file or a directory.')\n",
        "  sys.exit('Input not understood.')\n",
        "\n",
        "# Output\n",
        "if output_dir == '':\n",
        "  dir_out = dir_in\n",
        "else:\n",
        "  if not os.path.isdir(drive_root+output_dir):\n",
        "    os.mkdir(drive_root+output_dir)\n",
        "  dir_out = drive_root+fix_path(output_dir)\n",
        "  \n",
        "timer_start = time.time()\n",
        "total = len(inputs)\n",
        "\n",
        "if copy_files == True:\n",
        "  files = glob(dir_tmp)\n",
        "  for f in files:\n",
        "    os.remove(f)\n",
        "  for input in inputs:\n",
        "    shutil.copy(input, dir_tmp)\n",
        "  inputs = list_images(dir_tmp)\n",
        "  dir_in = dir_tmp\n",
        "\n",
        "\n",
        "\n",
        "using = 'GPU' if device == 'cuda' else 'CPU'\n",
        "total = len(inputs) * len(scales)\n",
        "count = 1\n",
        "\n",
        "est_time = est_per_img * total\n",
        "\n",
        "op(c.title, 'RUN ID:', uniq_id, time=True)\n",
        "op(c.okb, 'Using '+using+' to process '+str(total)+' images out of '+str(len(inputs))+' images', time=True)\n",
        "# op(c.okb, 'Estimated time:', timedelta(seconds=est_time), time=True)\n",
        "\n",
        "print()\n",
        "\n",
        "for input in inputs:\n",
        "  if output_dir == '' and include_subdirs is True:\n",
        "    dir_out = dir_in\n",
        "\n",
        "  ndx_info = str(count)+'/'+str(total)+' '\n",
        "  op(c.title, ndx_info+'Processing', path_leaf(input), time=True)\n",
        "\n",
        "  image_tensor, orig_size = load_image(input, hypar) \n",
        "  mask = predict(net, image_tensor, orig_size, hypar, device)\n",
        "\n",
        "  fd = filename_detail+'__' if filename_detail != '' else ''\n",
        "  file_out = dir_out+fd+slug(basename(input)[:trunc])+'x_'+uniq_id+'_'+model_name+'.png'\n",
        "\n",
        "  save_output(input, mask, file_out, contrast, save_mask)\n",
        "  if os.path.isfile(file_out):\n",
        "    op(c.ok, 'Saved as', path_leaf(dir_out)+'/'+path_leaf(file_out), time=True)\n",
        "  else:\n",
        "    op(c.fail, 'ERROR saving', file_out, time=True)\n",
        "\n",
        "  timer_pc = time.time()\n",
        "  elapsed = timer_pc-timer_start\n",
        "  est_remaining = est_time-elapsed\n",
        "  # op(c.okb, 'Est. time remaining', timedelta(seconds=est_remaining), time=True)\n",
        "  count += 1\n",
        "  print()\n",
        "  \n",
        "# -- END THINGS --\n",
        "\n",
        "timer_end = time.time()\n",
        "\n",
        "print()\n",
        "op(c.okb, 'Elapsed', timedelta(seconds=timer_end-timer_start), time=True)\n",
        "op(c.ok, 'FIN.')\n",
        "\n",
        "if disconnect_runtime_when_done is True: end_session()"
      ],
      "metadata": {
        "cellView": "form",
        "id": "UcqbAWAxyCU1"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}