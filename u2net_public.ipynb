{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "11bhjCUDzegFdB_bfViM2YnpHxwWmQNE9",
      "authorship_tag": "ABX9TyOKzPK3U/ULyUN5vfo9nTML",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "premium"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/olaviinha/NeuralBackgroundRemoval/blob/main/u2net_public.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wCskRiNym_LW"
      },
      "source": [
        "#<font face=\"Trebuchet MS\" size=\"6\">U²-Net<font color=\"#999\" size=\"4\">&nbsp;&nbsp;&nbsp;|&nbsp;&nbsp;&nbsp;</font><font color=\"#999\" size=\"4\">Background removal</font><font color=\"#999\" size=\"4\">&nbsp;&nbsp;&nbsp;|&nbsp;&nbsp;&nbsp;</font><a href=\"https://github.com/olaviinha/NeuralBackgroundRemoval\" target=\"_blank\"><font color=\"#999\" size=\"4\">Github</font></a>\n",
        "\n",
        "Colab for [U²-Net: Going Deeper with Nested U-Structure for Salient Object Detection](https://arxiv.org/pdf/2005.09007.pdf) by Xuebin Qin et al.\n",
        "\n",
        "<font color=\"salmon\">Note!</font> In light of Google Colab's recent price hike circus, please note that running this notebook is probably entirely tolerable on CPU only runtime (without GPU). Images are processed within seconds on CPU.\n",
        "\n",
        "### Tips\n",
        "\n",
        "- All directory and file paths should be relative to your Google Drive root: e.g. if you have a directory called _images_ in your Drive, containing a subdirectory called _churchboats_, then the field value in this notebook should be `images/churchboats`.\n",
        "\n",
        "- `input` may be a path to an image file or a directory containing image files. All images found from the directory will be individually processed (images in subdirs not included).\n",
        "\n",
        "- If you provide a `local_models_dir` path, all models will be fetched from there instead of being downloaded. If models are not found from the given path, they will be downloaded there first. Using this may be useful in the future if models are no longer available in their current locations.\n",
        "\n",
        "- `scalers` (~0-1) are factors for image resizing prior to processing. You may think of it as _background removal rate_ or  _sensitivity_ of the bg removal, where a higher number typically removes more stuff from the image. You may give a single value or a comma separated list of values (e.g. `0.5, 0.75`). Each given value will produce a new image.\n",
        "\n",
        "- `end_session_when_done` disconnects and deletes runtime upon cell completion. Mostly useful if you are processing a large number of images on a GPU runtime."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A6-8KXU6m8TM",
        "cellView": "form"
      },
      "source": [
        "#@title #Setup\n",
        "#@markdown This cell needs to be run only once. It will mount your Google Drive and setup prerequisites.<br>\n",
        "#@markdown <small>Mounting Drive will enable this notebook to save outputs directly to your Drive. Otherwise you will need to copy/download them manually from this notebook.</small>\n",
        "\n",
        "force_setup = False\n",
        "repositories = [\n",
        "  'https://github.com/xuebinqin/U-2-Net',\n",
        "  # 'https://github.com/xuebinqin/DIS'\n",
        "]\n",
        "pip_packages = ''\n",
        "apt_packages = ''\n",
        "mount_drive = True #@param {type:\"boolean\"}\n",
        "local_models_dir = \"\" #@param {type:\"string\"}\n",
        "skip_setup = False #@ param {type:\"boolean\"}\n",
        "\n",
        "# Download the repo from Github\n",
        "import os\n",
        "from google.colab import output\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "%cd /content/\n",
        "\n",
        "# inhagcutils\n",
        "if not os.path.isfile('/content/inhagcutils.ipynb') and force_setup == False:\n",
        "  !pip -q install import-ipynb {pip_packages}\n",
        "  if apt_packages != '':\n",
        "    !apt-get update && apt-get install {apt_packages}\n",
        "  !curl -s -O https://raw.githubusercontent.com/olaviinha/inhagcutils/master/inhagcutils.ipynb\n",
        "import import_ipynb\n",
        "from inhagcutils import *\n",
        "\n",
        "# Mount Drive\n",
        "if mount_drive is True:\n",
        "  if not os.path.isdir('/content/drive'):\n",
        "    from google.colab import drive\n",
        "    drive.mount('/content/drive')\n",
        "    drive_root = '/content/drive/My Drive'\n",
        "  if not os.path.isdir('/content/mydrive'):\n",
        "    os.symlink('/content/drive/My Drive', '/content/mydrive')\n",
        "    drive_root = '/content/mydrive/'\n",
        "  drive_root_set = True\n",
        "else:\n",
        "  create_dirs(['/content/faux_drive'])\n",
        "  drive_root = '/content/faux_drive/'\n",
        "\n",
        "if len(repositories) > 0:\n",
        "  if skip_setup == False:\n",
        "    for repo in repositories:\n",
        "      %cd /content/\n",
        "      install_dir = fix_path('/content/'+path_leaf(repo).replace('.git', ''))\n",
        "      repo_name = basename(install_dir)\n",
        "      repo = repo if '.git' in repo else repo+'.git'\n",
        "      !git clone {repo}\n",
        "      if os.path.isfile(install_dir+'setup.py') or os.path.isfile(install_dir+'setup.cfg'):\n",
        "        !pip install -e ./{install_dir}\n",
        "      if os.path.isfile(install_dir+'requirements.txt'):\n",
        "        !pip install -r {install_dir}/requirements.txt\n",
        "  else:\n",
        "    install_dir = fix_path('/content/'+path_leaf(repositories[0]).replace('.git', ''))\n",
        "    repo_name = path_leaf(install_dir)\n",
        "\n",
        "dir_tmp = '/content/tmp/'\n",
        "create_dirs([dir_tmp])\n",
        "\n",
        "if len(repositories) == 1:\n",
        "  %cd {install_dir}\n",
        "\n",
        "import time, sys\n",
        "from datetime import timedelta\n",
        "\n",
        "# # DO stuff\n",
        "# if repo_name == 'DIS':\n",
        "#   !gdown 1jOC2zK0GowBvEt03B7dGugCRDVAoeIqq\n",
        "\n",
        "def prep_model(model, gid):\n",
        "  global install_dir, models_dir\n",
        "  filename = model+'.pth'\n",
        "  if not os.path.isfile(models_dir+filename):\n",
        "    !gdown {gid}\n",
        "  if os.path.isfile(models_dir+filename):\n",
        "    mdir = install_dir+'saved_models/'+fix_path(basename(filename))\n",
        "    if not os.path.isdir(mdir): os.mkdir(mdir)\n",
        "    shutil.copy(models_dir+filename, mdir+filename)\n",
        "  else:\n",
        "    op(c.fail, 'Failed', filename)\n",
        "\n",
        "if local_models_dir != '':\n",
        "  models_dir = drive_root+fix_path(local_models_dir)\n",
        "  if not os.path.isdir(models_dir): os.mkdir(models_dir)\n",
        "  %cd {models_dir}\n",
        "  prep_model('u2net', '1ao1ovG1Qtx4b7EoskHXmi2E9rp5CHLcZ')\n",
        "  prep_model('u2netp', '1rbSTGKAE-MTxBYHd-51l2hMOQPT_7EPy')\n",
        "  prep_model('u2net_human_seg', '1-Yg0cxgrNhHP-016FPdp902BR-kSsA4P')\n",
        "  prep_model('u2net_portrait', '1IG3HdpcRiDoWNookbncQjeaPN28t90yW')\n",
        "  %cd {install_dir}\n",
        "else:\n",
        "  # u2net\n",
        "  d = install_dir+'saved_models/u2net'\n",
        "  os.mkdir(d)\n",
        "  %cd {d}\n",
        "  !gdown 1ao1ovG1Qtx4b7EoskHXmi2E9rp5CHLcZ\n",
        "  # u2netp\n",
        "  d = install_dir+'saved_models/u2netp'\n",
        "  os.mkdir(d)\n",
        "  %cd {d}\n",
        "  !gdown 1rbSTGKAE-MTxBYHd-51l2hMOQPT_7EPy\n",
        "  # human seg\n",
        "  d = install_dir+'saved_models/u2net_human_seg'\n",
        "  os.mkdir(d)\n",
        "  %cd {d}\n",
        "  !gdown 1-Yg0cxgrNhHP-016FPdp902BR-kSsA4P\n",
        "  # portrait\n",
        "  d = install_dir+'saved_models/u2net_portrait'\n",
        "  os.mkdir(d)\n",
        "  %cd {d}\n",
        "  !gdown 1IG3HdpcRiDoWNookbncQjeaPN28t90yW\n",
        "\n",
        "import os\n",
        "from skimage import io, transform\n",
        "import torch\n",
        "import torchvision\n",
        "from torch.autograd import Variable\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision import transforms#, utils\n",
        "# import torch.optim as optim\n",
        "\n",
        "import numpy as np\n",
        "from PIL import Image, ImageEnhance\n",
        "from glob import glob\n",
        "\n",
        "from data_loader import RescaleT\n",
        "from data_loader import ToTensor\n",
        "from data_loader import ToTensorLab\n",
        "from data_loader import SalObjDataset\n",
        "\n",
        "from model import U2NET # full size version 173.6 MB\n",
        "from model import U2NETP # small version u2net 4.7 MB\n",
        "\n",
        "# normalize the predicted SOD probability map\n",
        "def normPRED(d):\n",
        "  ma = torch.max(d)\n",
        "  mi = torch.min(d)\n",
        "  dn = (d-mi)/(ma-mi)\n",
        "  return dn\n",
        "\n",
        "def save_output(og_img, pred, output_path, contrast=1, save_mask=False):\n",
        "  predict = pred\n",
        "  predict = predict.squeeze()\n",
        "  predict_np = predict.cpu().data.numpy()\n",
        "  im = Image.fromarray(predict_np*255).convert('L')\n",
        "  og_image = io.imread(og_img)\n",
        "  mask = im.resize((og_image.shape[1],og_image.shape[0]), resample=Image.BILINEAR)\n",
        "  if contrast != 1:\n",
        "    enhancer = ImageEnhance.Contrast(mask)\n",
        "    mask = enhancer.enhance(contrast)\n",
        "  if save_mask is True:\n",
        "    mask.save(output_path.replace('.png', '_mask.png'), 'PNG')\n",
        "  im2 = Image.open(og_img)\n",
        "  im2.putalpha(mask)\n",
        "  im2.save(output_path, 'PNG')\n",
        "\n",
        "%cd {install_dir}\n",
        "\n",
        "output.clear()\n",
        "op(c.ok, 'Setup finished.')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H2z1os4Bocdy",
        "cellView": "form"
      },
      "source": [
        "#@title # Run\n",
        "include_subdirs = False #@ param {type: \"boolean\"}\n",
        "input = \"\" #@param {type:\"string\"}\n",
        "output_dir = \"\" #@param {type:\"string\"}\n",
        "\n",
        "filename_detail = \"\" # @param {type:\"string\"}\n",
        "\n",
        "scalers = \"0.5\" #@param {type:\"string\"}\n",
        "model = \"u2net\" #@param [\"u2net\", \"u2netp\", \"portrait\", \"human\"]\n",
        "disconnect_runtime_when_done = False #@param {type: \"boolean\"}\n",
        "\n",
        "contrast = 1\n",
        "save_mask = False\n",
        "\n",
        "model_path = install_dir+'saved_models/'+model+'/'+model+'.pth'\n",
        "model_name = basename(model_path)\n",
        "uniq_id = gen_id()\n",
        "trunc = 40\n",
        "est_per_img = 10\n",
        "\n",
        "copy_files = False\n",
        "exclude_images_containing = ['u2net', 'isnet']\n",
        "\n",
        "if os.path.isfile(drive_root+input):\n",
        "  inputs = [drive_root+input]\n",
        "  dir_in = path_dir(drive_root+input)\n",
        "  copy_files = True\n",
        "elif input != '' and os.path.isdir(drive_root+input):\n",
        "  dir_in = drive_root+fix_path(input)\n",
        "  inputs = list_images(dir_in, exclude_pattern=exclude_images_containing)\n",
        "  if include_subdirs is True:\n",
        "    dirlist = glob(dir_in+'/*')\n",
        "    for item in dirlist:\n",
        "      if os.path.isdir(item):\n",
        "        inputs.extend(list_images(item, exclude_pattern=exclude_images_containing))\n",
        "    # inputs = list(set(inputs))\n",
        "elif os.path.isdir(drive_root+input) and '*' in input:\n",
        "  dir_in = path_dir(drive_root+input)\n",
        "  inputs = glob(drive_root+input)\n",
        "  copy_files = True\n",
        "else:\n",
        "  op(c.fail, 'FAIL!', 'Input should be a path to a file or a directory.')\n",
        "  sys.exit('Input not understood.')\n",
        "\n",
        "# Output\n",
        "if output_dir == '':\n",
        "  dir_out = dir_in\n",
        "else:\n",
        "  if not os.path.isdir(drive_root+output_dir):\n",
        "    os.mkdir(drive_root+output_dir)\n",
        "  dir_out = drive_root+fix_path(output_dir)\n",
        "  \n",
        "timer_start = time.time()\n",
        "total = len(inputs)\n",
        "\n",
        "if copy_files == True:\n",
        "  files = glob(dir_tmp)\n",
        "  for f in files:\n",
        "    os.remove(f)\n",
        "  for input in inputs:\n",
        "    shutil.copy(input, dir_tmp)\n",
        "  inputs = list_images(dir_tmp)\n",
        "  dir_in = dir_tmp\n",
        "\n",
        "scales = [float(scale.strip()) for scale in scalers.split(',')]\n",
        "\n",
        "# -- DO THINGS --\n",
        "\n",
        "if(model_name=='u2net'):\n",
        "  net = U2NET(3,1)\n",
        "elif(model_name=='u2netp'):\n",
        "  net = U2NETP(3,1)\n",
        "\n",
        "using = 'CPU'\n",
        "if torch.cuda.is_available():\n",
        "  net.load_state_dict(torch.load(model_path))\n",
        "  net.cuda()\n",
        "  using = 'GPU'\n",
        "else:\n",
        "  net.load_state_dict(torch.load(model_path, map_location='cpu'))\n",
        "net.eval()\n",
        "\n",
        "total = len(inputs) * len(scales)\n",
        "count = 1\n",
        "est_time = est_per_img * total\n",
        "\n",
        "op(c.title, 'RUN ID:', uniq_id, time=True)\n",
        "op(c.okb, 'Using '+using+' to process '+str(total)+' images out of '+str(len(inputs))+' images', time=True)\n",
        "# op(c.okb, 'Estimated time:', timedelta(seconds=est_time), time=True)\n",
        "print()\n",
        "\n",
        "for input in inputs:\n",
        "  if output_dir == '' and include_subdirs is True:\n",
        "    dir_out = dir_in\n",
        "  for scale in scales:\n",
        "    ndx_info = str(count)+'/'+str(total)+' '\n",
        "    op(c.title, ndx_info+'Processing', path_leaf(input), time=True)\n",
        "    inp = Image.open(input)\n",
        "    w, h = inp.size\n",
        "    max_side = int(max([w, h])*scale)\n",
        "    # print( max_side )\n",
        "    fd = filename_detail+'__' if filename_detail != '' else ''\n",
        "    salobj_dataset = SalObjDataset(img_name_list=[input], lbl_name_list=[], transform=transforms.Compose([RescaleT(max_side), ToTensorLab(flag=0)]) )\n",
        "    salobj_dataloader = DataLoader(salobj_dataset, batch_size=1, shuffle=False, num_workers=1)\n",
        "    for i, data in enumerate(salobj_dataloader):\n",
        "      file_out = dir_out+fd+slug(basename(input)[:trunc])+'x_'+uniq_id+'_'+model_name+'_'+str(scale).replace('.','')+'.png'\n",
        "      # print( 'save as', file_out)\n",
        "      inputs_test = data['image']\n",
        "      inputs_test = inputs_test.type(torch.FloatTensor)\n",
        "      if torch.cuda.is_available():\n",
        "        inputs_test = Variable(inputs_test.cuda())\n",
        "      else:\n",
        "        inputs_test = Variable(inputs_test)\n",
        "      d1,d2,d3,d4,d5,d6,d7= net(inputs_test)\n",
        "      pred = d1[:,0,:,:]\n",
        "      pred = normPRED(pred)\n",
        "      save_output(input, pred, file_out, contrast, save_mask)\n",
        "      if os.path.isfile(file_out):\n",
        "        op(c.ok, 'Saved as', path_leaf(dir_out)+'/'+path_leaf(file_out), time=True)\n",
        "      else:\n",
        "        op(c.fail, 'ERROR saving', file_out, time=True)\n",
        "      del d1,d2,d3,d4,d5,d6,d7,pred\n",
        "      timer_pc = time.time()\n",
        "      elapsed = timer_pc-timer_start\n",
        "      est_remaining = est_time-elapsed\n",
        "      # op(c.okb, 'Est. time remaining', timedelta(seconds=est_remaining), time=True)\n",
        "    del salobj_dataset, salobj_dataloader, inp\n",
        "    count += 1\n",
        "    print()\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "  \n",
        "# -- END THINGS --\n",
        "\n",
        "timer_end = time.time()\n",
        "\n",
        "print()\n",
        "op(c.okb, 'Elapsed', timedelta(seconds=timer_end-timer_start), time=True)\n",
        "op(c.ok, 'FIN.')\n",
        "\n",
        "if disconnect_runtime_when_done is True: end_session()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}